{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c46faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4f10f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "papers_editors_fields = pd.read_csv(\"Z:/capstone_data/editors_and_their_papers.csv\", index_col = 'Unnamed: 0')\n",
    "fields_children = pd.read_csv(\"Z:\\capstone_data\\\\advanced\\FieldOfStudyChildren.txt\", sep=\"\\t\", header = None, names=['parent', 'child'])\n",
    "fields = pd.read_csv(\"Z:\\capstone_data\\\\advanced\\FieldsOfStudy.txt\", sep=\"\\t\", header = None, names=['parent', 'parent_level'], usecols=[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "09b6a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_editors_fields = papers_editors_fields[papers_editors_fields['Score'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe that associates fields by parent-child relationships and gives the parent's level (0 to 5)\n",
    "def get_fields_data(fields, fields_children): #read from fieldofstudy and fieldofstudychildren respectively\n",
    "    new_fields = pd.merge(fields_children, fields, on='parent', how='left')\n",
    "    return new_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15193dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with columns child and parent_info (dict of id: level)\n",
    "def map_child_to_parent_fields(fields): # takes dataframe and returns graph \n",
    "\n",
    "    fields['parent_info'] = list(zip(fields.parent, fields.parent_level))\n",
    "    df = fields[['child', 'parent_info']].groupby('child')['parent_info'].agg(lambda x: dict((a, b) for a, b in x)).reset_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2023235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of all zero level fields for a given field (v)\n",
    "def depth_first_search(graph, v, visited):\n",
    "    stack = [v]\n",
    "    zero_level_fields = set()\n",
    "    \n",
    "    while stack:\n",
    "        v = stack.pop()\n",
    "        \n",
    "        if v in visited:\n",
    "            continue\n",
    "            \n",
    "        visited.add(v)\n",
    "\n",
    "        if v in graph:\n",
    "            for parent in graph[v].keys():\n",
    "                if graph[v][parent] == 0:\n",
    "                    zero_level_fields.add(parent)\n",
    "                else:\n",
    "                    stack.append(parent)\n",
    "    \n",
    "    return list(zero_level_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb14e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns graph(dict of lists) structure with format ```field : [zero level fields]```\n",
    "def map_field_to_zero_level_field(child_to_parent_fields_mapping, fields):\n",
    "    \n",
    "    child_parent_fields = child_to_parent_fields_mapping.to_dict('split')['data']\n",
    "    \n",
    "    graph = {i[0]: i[1] for i in child_parent_fields}\n",
    "    \n",
    "    zero_level_fields_mapping = {}\n",
    "    \n",
    "    for index, row in fields.iterrows():\n",
    "        field = row['child']\n",
    "        zero_level_fields = depth_first_search(graph, field, set())           \n",
    "        zero_level_fields_mapping[field] = zero_level_fields\n",
    "    \n",
    "    \n",
    "    return zero_level_fields_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45453101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_to_dict(x):\n",
    "    tracker = {}\n",
    "    for a, b in x:\n",
    "        tracker[a] = tracker.get(a, 0) + b\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b866e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns dataframe with paper data and column of {zerolevelfield: summed score, etc.}\n",
    "def map_papers_to_fields(papers, zero_level_fields):\n",
    "    \n",
    "    paper_fields_mapping = pd.merge(papers, zero_level_fields, on='FieldId', how='left')\n",
    "        \n",
    "    paper_fields_mapping['ZeroLevelFieldsScores'] = list(zip(paper_fields_mapping.ParentIds, paper_fields_mapping.Score))\n",
    "    paper_fields_mapping = paper_fields_mapping.dropna(0)\n",
    "    #indexing [1:-1] and splitting cleans the ids because they are treated as strings\n",
    "    paper_fields_mapping['ZeroLevelFieldsScores'] = paper_fields_mapping.apply(lambda x: list((a, x.ZeroLevelFieldsScores[1]) for a in x.ZeroLevelFieldsScores[0][1:-1].split(', ')), axis=1)\n",
    "    df = paper_fields_mapping.groupby('PaperId')['ZeroLevelFieldsScores'].agg(lambda x : x.values.tolist()).reset_index()\n",
    "    df['ZeroLevelFieldsScores'] = df['ZeroLevelFieldsScores'].apply(lambda lst: list([x for l in lst for x in l]))\n",
    "    df['ZeroLevelFieldsScores'] = df['ZeroLevelFieldsScores'].apply(collapse_to_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07bcbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_field(authors_papers, this_author): #using all the papers that an academic has authored, get their level 0 field\n",
    "    \n",
    "    #step 1: get all an author's papers\n",
    "    this_author = authors_papers[authors_papers['AuthorId'] == this_author]\n",
    "    \n",
    "    #step 2: sum the level 0 fields and probabilities of all those papers\n",
    "    scores = {}\n",
    "    for index, row in this_author.iterrows():\n",
    "        for field, score in row['ZeroLevelFieldsScores'].items():\n",
    "            scores[field] = scores.get(field, 0) + score \n",
    "\n",
    "    return max([(value, key) for key, value in scores.items()])[1] if scores else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "930fceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_journal_field(journal_papers, this_journal): #using all the papers that an academic has authored, get their level 0 field\n",
    "    \n",
    "    #step 1: get all a journal's papers\n",
    "    this_journal_df = journal_papers[journal_papers['JournalId'] == this_journal]\n",
    "    \n",
    "    #step 2: sum the level 0 fields and probabilities of all those papers\n",
    "    scores = {}\n",
    "    for index, row in this_journal_df.iterrows():\n",
    "        for field, score in row['ZeroLevelFieldsScores'].items():\n",
    "            scores[field] = scores.get(field, 0) + score \n",
    "\n",
    "    return max([(value, key) for key, value in scores.items()])[1] if scores else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18546bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***uncomment if running from scratch\n",
    "new_fields = get_fields_data(fields, fields_children)\n",
    "mapping = map_child_to_parent_fields(new_fields)\n",
    "zero_level_fields_mapping = map_field_to_zero_level_field(mapping, new_fields)\n",
    "flds, prnts = zip(*zero_level_fields_mapping.items())\n",
    "zero_level_df = pd.DataFrame({'FieldId': flds, 'ParentIds': prnts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f999f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero_level_df.to_csv('./zero_level_mapping.csv')\n",
    "zero_level_df = pd.read_csv('zero_level_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "149a9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_fields = map_papers_to_fields(papers_editors_fields, zero_level_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "180adc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_papers = pd.merge(papers_editors_fields, papers_fields, on='PaperId' , how='inner').drop(['FieldId', 'Score'], axis=1).drop_duplicates(subset=['PaperId', 'AuthorId'])\n",
    "authors_fields = pd.DataFrame(columns= ['AuthorId', 'FieldPrediction'])\n",
    "for author in papers_editors_fields['AuthorId'].unique():\n",
    "    field_prediction = get_author_field(authors_papers, author)\n",
    "    authors_fields.loc[len(authors_fields.index)] = [int(author), field_prediction] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2fc3b28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>FieldPrediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278406758</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014284122</td>\n",
       "      <td>15744967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222372278</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2640940786</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2107252006</td>\n",
       "      <td>71924100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52767</th>\n",
       "      <td>2686191159</td>\n",
       "      <td>33923547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52768</th>\n",
       "      <td>3008005074</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52769</th>\n",
       "      <td>2488279845</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52770</th>\n",
       "      <td>3019503342</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52771</th>\n",
       "      <td>1988947924</td>\n",
       "      <td>86803240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52772 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AuthorId FieldPrediction\n",
       "0      2278406758        86803240\n",
       "1      2014284122        15744967\n",
       "2      2222372278        86803240\n",
       "3      2640940786        86803240\n",
       "4      2107252006        71924100\n",
       "...           ...             ...\n",
       "52767  2686191159        33923547\n",
       "52768  3008005074        86803240\n",
       "52769  2488279845        86803240\n",
       "52770  3019503342        86803240\n",
       "52771  1988947924        86803240\n",
       "\n",
       "[52772 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_fields.to_csv('authors_fields_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3f25f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_journals = pd.read_csv(\"Z:/papers_journals.csv\", index_col = 'Unnamed: 0', nrows=100000).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "88449679",
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_papers = pd.merge(papers_journals, papers_fields, on='PaperId', how='inner').drop_duplicates(subset=['PaperId'])\n",
    "journals_fields = pd.DataFrame(columns= ['JournalId', 'FieldPrediction'])\n",
    "for journal in papers_journals['JournalId'].unique():\n",
    "    field_prediction = get_journal_field(journals_papers, journal)\n",
    "    journals_fields.loc[len(journals_fields.index)] = [str(journal), field_prediction] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4328f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "journals_fields.to_csv('journals_fields_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47323c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
